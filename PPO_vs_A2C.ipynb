{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeccab97-111c-4eb2-ad7f-2515534b522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sb3_contrib import MaskablePPO\n",
    "from sb3_contrib.common.maskable.policies import MaskableActorCriticPolicy\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "\n",
    "import gymnasium as gym\n",
    "import pygame\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import stable_baselines3\n",
    "import pettingzoo\n",
    "#from stable_baselines3 import A2C\n",
    "\n",
    "from stable_baselines3.common.sb2_compat.rmsprop_tf_like import RMSpropTFLike\n",
    "\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72a13539-9068-4831-aa4a-2becbf2455de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Implement_A2C.ipynb\n",
    "latest_policy = max(glob.glob(f\"{'othello_A2C'}*.zip\"), key=os.path.getctime)\n",
    "model_A2C = A2C.load(path=latest_policy)\n",
    "model_A2C.set_random_seed(8)\n",
    "\n",
    "%run MaskablePPO.ipynb\n",
    "latest_policy = max(glob.glob(f\"{'othello_PPO'}*.zip\"), key=os.path.getctime)\n",
    "model_PPO = MaskablePPO.load(path=latest_policy)\n",
    "model_PPO.set_random_seed(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "700cef0c-b17b-41ed-bc84-6e4929964d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Based on - \n",
    "Author: Elliot (https://github.com/elliottower)\n",
    "URL: https://github.com/Farama-Foundation/PettingZoo/blob/master/tutorials/SB3/connect_four/sb3_connect_four_action_mask.py\n",
    "\"\"\"\n",
    "\n",
    "def validate(num_games):\n",
    "    %run Othello.ipynb\n",
    "    env = OthelloEnv()\n",
    "    \n",
    "    scores = {agent: 0 for agent in env.possible_agents}\n",
    "    total_rewards = {agent: 0 for agent in env.possible_agents}\n",
    "    round_rewards = []\n",
    "\n",
    "    for i in range(num_games):\n",
    "        env.reset(seed=i)\n",
    "        env.action_space(env.possible_agents[0]).seed(i)\n",
    "\n",
    "        #env.random_agent_selection()\n",
    "        PPO_player = env.agent_selection\n",
    "        A2C_player = env.select_next(PPO_player)\n",
    "\n",
    "        agent = env.agent_selection\n",
    "\n",
    "        while True:\n",
    "            obs, reward, termination, truncation, info = env.last()\n",
    "\n",
    "            # Separate observation and action mask\n",
    "            observation, action_mask = obs.values()\n",
    "\n",
    "            if termination or truncation:\n",
    "                # If there is a winner, keep track, otherwise don't change the scores (tie)\n",
    "                if (\n",
    "                    env.rewards[env.possible_agents[0]]\n",
    "                    != env.rewards[env.possible_agents[1]]\n",
    "                ):\n",
    "                    winner = max(env.rewards, key=env.rewards.get)\n",
    "                    scores[winner] += env.rewards[\n",
    "                        winner\n",
    "                    ]  # only tracks the largest reward (winner of game)\n",
    "                # Also track negative and positive rewards (penalizes illegal moves)\n",
    "                for a in env.possible_agents:\n",
    "                    total_rewards[a] += env.rewards[a]\n",
    "                # List of rewards by round, for reference\n",
    "                round_rewards.append(env.rewards)\n",
    "                break\n",
    "            else:\n",
    "                if agent == PPO_player:\n",
    "                    act = int(\n",
    "                        model_PPO.predict(\n",
    "                            observation, action_masks=action_mask, deterministic=True\n",
    "                        )[0]\n",
    "                    )\n",
    "                else:\n",
    "                    # Note: PettingZoo expects integer actions # TODO: change chess to cast actions to type int?\n",
    "                    act = int(\n",
    "                        model_A2C.predict(\n",
    "                            observation, action_masks=action_mask, deterministic=True\n",
    "                        )[0]\n",
    "                    )\n",
    "            env.step(act)\n",
    "    env.close()\n",
    "\n",
    "    count=0\n",
    "    for round in round_rewards:\n",
    "        if round[PPO_player] > round[A2C_player]:\n",
    "            count+=1\n",
    "    winrate = count/num_games\n",
    "        \n",
    "    return winrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ede8198-a16a-447d-8615-e977842170be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.497"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23c4d46-625a-4afb-a18a-75df32d0941f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
